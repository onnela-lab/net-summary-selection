{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from cost_based_selection import preprocessing_utils\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "import itertools as it\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 144\n",
    "mpl.style.use('../scrartcl.mplstyle')\n",
    "\n",
    "# Which model to generate figures for\n",
    "MODEL = os.environ.get('MODEL', 'ba')\n",
    "# Methods to consider.\n",
    "METHODS = (\n",
    "    'JMI JMIM mRMR reliefF_l1 reliefF_rf pen_rf_importance_impurity pen_rf_importance_permutation '\n",
    "    'weighted_rf_importance_impurity weighted_rf_importance_permutation random_ranking'\n",
    ").split()\n",
    "# The split that was used to identify features (always evaluated on the test set). This flag\n",
    "# is useful for looking at different number of nodes with pilot simulations.\n",
    "SPLIT = \"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e30b146",
   "metadata": {},
   "source": [
    "# Cost regularization.\n",
    "\n",
    "Figures for the section on cost-based methods with a penalty parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results for all methods.\n",
    "results_by_method = {}\n",
    "for method in METHODS:\n",
    "    with open(f'../workspace/{MODEL}/evaluation/{SPLIT}/{method}.pkl', 'rb') as fp:\n",
    "        results_by_method[method] = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc61a25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_cost_map(result, ax=None, debug=False, cost_levels=None, colorbar=None,\n",
    "                           xlabel=r'Penalty $\\lambda$', ylabel=r'Number of features $k$',\n",
    "                           noise_marker='o', vmin=None, clabel_fmt=\"%1.3f\", linscale=0.25):\n",
    "    \"\"\"\n",
    "    Plot the accuracy heat map with cost contours.\n",
    "    \n",
    "    Args:\n",
    "        \n",
    "    \"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    cost_levels = cost_levels or [0.01, 0.05, 0.1, 0.2]\n",
    "    \n",
    "    # Plot the accuracies\n",
    "    accuracies = result['accuracy']\n",
    "    cumulative_costs = result['normalized_cumulative_costs']\n",
    "    penalties = result['penalties']\n",
    "    num_features = 1 + np.arange(accuracies.shape[1])\n",
    "    im = ax.pcolormesh(penalties, num_features, accuracies.mean(axis=-1).T, rasterized=True,\n",
    "                       vmax=1, vmin=vmin or min(.95, accuracies.mean(axis=-1).min()))\n",
    "\n",
    "    # Plot the cumulative cost levels.\n",
    "    cs = ax.contour(penalties, num_features, cumulative_costs.T, levels=cost_levels, colors='k')\n",
    "    \n",
    "    # Get the noise features.\n",
    "    noise_features = np.char.startswith(result['features'], 'noise')\n",
    "    noise_features = noise_features[result['rankings']][:, :accuracies.shape[1]]\n",
    "    x, y = np.nonzero(noise_features)\n",
    "    pts = ax.scatter(penalties[x], 1 + y, marker=noise_marker)\n",
    "    pts.set_edgecolor('w')\n",
    "    \n",
    "    # ax.set_title(key)\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "    linthresh = penalties[1] / 2\n",
    "    ax.set_xscale('symlog', linthresh=linthresh, linscale=linscale)\n",
    "    ax.axvline(linthresh, color='k', ls=':')\n",
    "    \n",
    "    plt.clabel(cs, fmt=clabel_fmt)\n",
    "    \n",
    "    ticks = ax.get_xticks()\n",
    "    ticks[1] = ticks[0]\n",
    "    ax.set_xticks(ticks[1:])\n",
    "    \n",
    "    if colorbar:\n",
    "        cb = fig.colorbar(im, ax=ax, location=colorbar)\n",
    "        cb.set_label('Accuracy')\n",
    "        cb.locator = mpl.ticker.MaxNLocator(5)\n",
    "        cb.update_ticks()\n",
    "\n",
    "    if debug:\n",
    "        ax.axvline(linthresh)\n",
    "        ax.scatter(penalties, np.ones_like(penalties), marker='x', color='C1')\n",
    "        \n",
    "    return im\n",
    "\n",
    "\n",
    "# Show for one method as an example.\n",
    "key = \"JMI\"\n",
    "fig, ax = plt.subplots()\n",
    "plot_accuracy_cost_map(results_by_method[key], colorbar='right')\n",
    "ax.set_title(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef92ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the four-panel figures for different methods.\n",
    "configs_list = [\n",
    "    {\n",
    "        \"JMI\": {\n",
    "            \"label\": {\n",
    "                \"s\": \"(a)\",\n",
    "                \"x\": 0.05,\n",
    "                \"y\": 0.95,\n",
    "                \"va\": \"top\",\n",
    "            },\n",
    "            \"levels\": [0.01, 0.05, 0.2]\n",
    "        },\n",
    "        \"mRMR\": {\n",
    "            \"label\": {\n",
    "                \"s\": \"(b)\",\n",
    "                \"x\": 0.05,\n",
    "                \"y\": 0.95,\n",
    "                \"va\": \"top\",\n",
    "            },\n",
    "            \"levels\": [0.001, 0.01, 0.05]\n",
    "        }, \n",
    "        \"reliefF_l1\": {\n",
    "            \"label\": {\n",
    "                \"s\": \"(c)\",\n",
    "                \"x\": 0.95 if MODEL == \"ba\" else 0.05,\n",
    "                \"y\": 0.05 if MODEL == \"ba\" else 0.95,\n",
    "                \"ha\": \"right\" if MODEL == \"ba\" else \"left\",\n",
    "                \"va\": \"bottom\" if MODEL == \"ba\" else \"top\",\n",
    "            }\n",
    "        }, \n",
    "        \"pen_rf_importance_permutation\": {\n",
    "            \"label\": {\n",
    "                \"s\": \"(d)\",\n",
    "                \"x\": 0.05,\n",
    "                \"y\": 0.95,\n",
    "                \"va\": \"top\",\n",
    "            },\n",
    "            \"levels\": [0.01, 0.05, 0.2]\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"JMIM\": {\n",
    "            \"label\": {\n",
    "                \"s\": \"(a)\",\n",
    "                \"x\": 0.05,\n",
    "                \"y\": 0.95,\n",
    "                \"va\": \"top\",\n",
    "            },\n",
    "        },\n",
    "        \"reliefF_rf\": {\n",
    "            \"label\": {\n",
    "                \"s\": \"(b)\",\n",
    "                \"x\": 0.05,\n",
    "                \"y\": 0.95,\n",
    "                \"va\": \"top\",\n",
    "            },\n",
    "        },\n",
    "        \"weighted_rf_importance_permutation\": {\n",
    "            \"label\": {\n",
    "                \"s\": \"(c)\",\n",
    "                \"x\": 0.05,\n",
    "                \"y\": 0.95,\n",
    "                \"va\": \"top\",\n",
    "            },\n",
    "        },\n",
    "        \"pen_rf_importance_impurity\": {\n",
    "            \"label\": {\n",
    "                \"s\": \"(d)\",\n",
    "                \"x\": 0.05,\n",
    "                \"y\": 0.95,\n",
    "                \"va\": \"top\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "for offset, configs in enumerate(configs_list):\n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(2, 3, width_ratios=[1, 1, .05])\n",
    "    ax = None\n",
    "    axes = []\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax = fig.add_subplot(gs[i, j], sharex=ax, sharey=ax)\n",
    "            axes.append(ax)\n",
    "            if i == 0:\n",
    "                plt.setp(ax.get_xticklabels(), visible=False)\n",
    "            else:\n",
    "                ax.set_xlabel(r\"Cost regularization $\\lambda$\")\n",
    "\n",
    "            if j == 1:\n",
    "                plt.setp(ax.get_yticklabels(), visible=False)\n",
    "            else:\n",
    "                ax.set_ylabel(\"Number of features $k$\")\n",
    "\n",
    "    cax = fig.add_subplot(gs[:, 2])\n",
    "\n",
    "    locator = mpl.ticker.MaxNLocator(integer=True)\n",
    "    for ax, (key, config) in zip(axes, configs.items()):\n",
    "        im = plot_accuracy_cost_map(\n",
    "            results_by_method[key], ax=ax, colorbar=False, clabel_fmt=None,\n",
    "            xlabel=None, ylabel=None, vmin=0.5, cost_levels=config.get(\"levels\"),\n",
    "            linscale=0.5,\n",
    "        )\n",
    "        ax.yaxis.set_major_locator(locator)\n",
    "        ax.text(**config['label'], transform=ax.transAxes)\n",
    "        print(key)\n",
    "\n",
    "    fig.colorbar(im, cax=cax).set_label(\"Accuracy\")\n",
    "    fig.tight_layout()\n",
    "    filename = f\"{MODEL}-accuracy-matrix-{offset}.pdf\"\n",
    "    fig.savefig(filename)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e340a",
   "metadata": {},
   "source": [
    "# Pilot simulations\n",
    "\n",
    "Figures for the cost of pilot simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5510980",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = 100 * (1 + np.arange(10))\n",
    "seeds = np.arange(5)\n",
    "configs = [\n",
    "    (method, f'../workspace/{MODEL}/evaluation/pilot/num_nodes-{num_nodes}/seed-{seed}/{method}.pkl')\n",
    "    for method, num_nodes, seed in it.product(METHODS, sizes, seeds)\n",
    "]\n",
    "results_by_method = {}\n",
    "accuracies_by_method = {}\n",
    "for method, filename in configs:\n",
    "    with open(filename, 'rb') as fp:\n",
    "        result = pickle.load(fp)\n",
    "    results_by_method.setdefault(method, []).append(result)\n",
    "        \n",
    "    # Verify shape; we have one cost regularization (lambda=0), up to fifteen different features,\n",
    "    # and ten-fold cross validation.\n",
    "    accuracy = result[\"accuracy\"]\n",
    "    assert accuracy.shape == (1, 15, 10)\n",
    "    \n",
    "    # We average over cross validation dimensions and pick the single seed.\n",
    "    accuracy = accuracy[0].mean(axis=-1)\n",
    "    accuracies_by_method.setdefault(method, []).append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify accuracy didn't decrease independent of size.\n",
    "fig, ax = plt.subplots()\n",
    "num_features = 5\n",
    "\n",
    "for method, accuracy in accuracies_by_method.items():\n",
    "    accuracy = np.asarray(accuracy).reshape((len(sizes), len(seeds), -1))\n",
    "    ys = accuracy[..., num_features - 2]\n",
    "    y = ys.mean(axis=-1)\n",
    "    line, = ax.plot(sizes, y, label=method)\n",
    "    l, u = np.quantile(ys, [0, 1], axis=-1)\n",
    "    ax.fill_between(sizes, l, u, color=line.get_color(), alpha=0.2)\n",
    "    \n",
    "ax.legend(loc='best', fontsize='small', ncol=2)\n",
    "ax.set_xlabel('Number of nodes in pilot simulation')\n",
    "ax.set_ylabel('Classification accuracy')\n",
    "ax.set_ylim(0.95)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45089b2972295b92c5c89083dd4caa228f1fdbf8ca3ea8faf3109ba7ae28a84a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
